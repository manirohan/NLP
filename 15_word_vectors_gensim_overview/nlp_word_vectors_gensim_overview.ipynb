{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33252ddf",
   "metadata": {},
   "source": [
    "<h3>NLP Tutorial: Word Vectors Overview Using Gensim Library</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a0003a",
   "metadata": {},
   "source": [
    "All gensim models are listed on this page: https://github.com/RaRe-Technologies/gensim-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82646d75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------------------] 1.4% 23.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=-------------------------------------------------] 3.8% 63.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===-----------------------------------------------] 6.4% 106.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====----------------------------------------------] 8.7% 144.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====---------------------------------------------] 11.0% 183.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======--------------------------------------------] 13.3% 220.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======-------------------------------------------] 15.5% 257.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========------------------------------------------] 17.7% 294.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========----------------------------------------] 20.1% 333.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========---------------------------------------] 22.5% 373.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============--------------------------------------] 25.0% 416.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============-------------------------------------] 27.6% 459.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============-----------------------------------] 30.2% 502.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================----------------------------------] 32.9% 546.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================---------------------------------] 35.4% 588.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================-------------------------------] 38.0% 632.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================-------------------------------] 40.0% 664.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================------------------------------] 40.9% 680.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================-----------------------------] 42.4% 704.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================----------------------------] 44.2% 735.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================---------------------------] 46.7% 776.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================--------------------------] 49.2% 817.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================-------------------------] 51.4% 854.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================------------------------] 53.5% 889.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================----------------------] 56.2% 935.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================---------------------] 59.1% 983.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================--------------------] 61.9% 1028.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================------------------] 64.6% 1073.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================-----------------] 67.0% 1113.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================----------------] 69.4% 1154.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================================---------------] 71.9% 1196.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================================-------------] 74.2% 1233.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================================-------------] 75.5% 1255.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================================------------] 76.8% 1276.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================================------------] 77.7% 1292.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================================-----------] 78.8% 1309.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================================-----------] 79.8% 1327.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================----------] 80.9% 1345.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================================---------] 82.8% 1376.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================================--------] 84.9% 1411.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========================================-------] 87.4% 1453.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================================-----] 90.2% 1499.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================================----] 93.0% 1547.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============================================---] 96.0% 1596.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 98.9% 1644.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 100.0% 1662.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "# This is a huge model (~1.6 gb) and it will take some time to load\n",
    "\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "123d8ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.729151"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1=\"great\", w2=\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74496bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.7291508913040161),\n",
       " ('bad', 0.7190051078796387),\n",
       " ('terrific', 0.6889115571975708),\n",
       " ('decent', 0.6837348937988281),\n",
       " ('nice', 0.6836092472076416),\n",
       " ('excellent', 0.644292950630188),\n",
       " ('fantastic', 0.6407778263092041),\n",
       " ('better', 0.6120728850364685),\n",
       " ('solid', 0.5806035399436951),\n",
       " ('lousy', 0.576420247554779)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e692b6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dogs', 0.8680489659309387),\n",
       " ('puppy', 0.8106428384780884),\n",
       " ('pit_bull', 0.7803961038589478),\n",
       " ('pooch', 0.7627376914024353),\n",
       " ('cat', 0.7609457969665527),\n",
       " ('golden_retriever', 0.7500901818275452),\n",
       " ('German_shepherd', 0.7465174198150635),\n",
       " ('Rottweiler', 0.7437615394592285),\n",
       " ('beagle', 0.7418621778488159),\n",
       " ('pup', 0.7406911253929138)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81ce92a4-fa01-4496-b611-5dbccc1980f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bags', 0.797116756439209),\n",
       " ('plastic_bag', 0.6741895079612732),\n",
       " ('suitcase', 0.6715359687805176),\n",
       " ('backpack', 0.6415843963623047),\n",
       " ('satchel', 0.6395978927612305),\n",
       " ('duffel_bag', 0.6315454840660095),\n",
       " ('duffle_bag', 0.609902560710907),\n",
       " ('Ziploc_bag', 0.6056379675865173),\n",
       " ('toiletry_bag', 0.5976647734642029),\n",
       " ('tote_bag', 0.5957799553871155)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('bag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ec84cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071),\n",
       " ('monarch', 0.6189674735069275),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321243286133)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6b2589c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chennai', 0.5442506074905396),\n",
       " ('delhi', 0.5149927139282227),\n",
       " ('mumbai', 0.5024341344833374),\n",
       " ('hyderabad', 0.49932482838630676),\n",
       " ('gujarat', 0.48732805252075195)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['paris', 'india'], negative=['france'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b60309d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.doesnt_match([\"facebook\", \"cat\", \"google\", \"microsoft\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8abe1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.doesnt_match([\"dog\", \"cat\", \"google\", \"mouse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df9555",
   "metadata": {},
   "source": [
    "<h3>Gensim: Glove</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46540508",
   "metadata": {},
   "source": [
    "Stanford's page on GloVe: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d31b2bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========---------------------------------------] 22.4% 23.4/104.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================================--------] 85.5% 89.6/104.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glv = api.load(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cbf5e30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('too', 0.9648017287254333),\n",
       " ('day', 0.9533665180206299),\n",
       " ('well', 0.9503171443939209),\n",
       " ('nice', 0.9438972473144531),\n",
       " ('better', 0.9425961971282959),\n",
       " ('fun', 0.9418926239013672),\n",
       " ('much', 0.9413353800773621),\n",
       " ('this', 0.9387555122375488),\n",
       " ('hope', 0.9383508563041687),\n",
       " ('great', 0.9378516674041748)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1b47c704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "99e10b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.doesnt_match(\"facebook cat google microsoft\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0ce3f7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'human'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glv.doesnt_match(\"banana grapes orange human\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21b5ace3-4c3e-4381-80a9-610cdabab61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification using wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d39afd1c-a7fd-4138-955f-14a768a8a8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.729151"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1='great',w2='good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0137ac7a-7b59-4440-b5f7-a8f9a90488c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ea86c06-5b97-4f3d-8637-fab0fb9cc507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake_and_real_news-Copy1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43186911-9781-448b-b91c-1c99e577a28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n",
       "1  U.S. conservative leader optimistic of common ...  Real\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake\n",
       "4  Democrats say Trump agrees to work on immigrat...  Real"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0c8b772-35c3-41a4-9877-748cb91fc58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fake    5000\n",
       "Real    4900\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d043c8a0-3078-49ad-b363-78d809b716f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label  label_num\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake          0\n",
       "1  U.S. conservative leader optimistic of common ...  Real          1\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real          1\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake          0\n",
       "4  Democrats say Trump agrees to work on immigrat...  Real          1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_num'] = df['label'].map({'Fake':0,'Real':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "82948490-ef69-47fe-ac1a-d95465b494b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_lg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2d6afe06-8807-4a66-8804-99d553fa8f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.60754453e-02,  4.50958544e-03,  3.99527289e-02,  1.03301011e-01,\n",
       "        1.27071934e-02,  3.88756581e-02, -5.71407704e-03, -3.27869877e-02,\n",
       "        1.64951030e-02,  8.31391942e-03, -3.64816003e-02, -6.60067424e-02,\n",
       "       -3.50894891e-02,  1.00541310e-02, -7.13332519e-02,  3.94097380e-02,\n",
       "        9.32050124e-02,  2.30641454e-03, -1.03801917e-02,  1.03007043e-02,\n",
       "       -8.04533530e-03,  3.02239526e-02,  5.26427515e-02, -2.30727647e-03,\n",
       "        1.40714599e-02,  1.22347446e-02,  1.61984880e-02, -1.92036312e-02,\n",
       "        6.25513121e-03, -5.48496991e-02, -7.00695114e-03,  1.33952638e-02,\n",
       "       -1.70304049e-02, -1.25543615e-02, -5.33353277e-02, -3.59208435e-02,\n",
       "       -4.56837146e-03,  8.47795885e-03,  3.39276381e-02,  1.81189198e-02,\n",
       "        4.95001227e-02, -2.63509620e-02,  8.22172388e-02, -1.38264196e-02,\n",
       "       -3.17617245e-02, -2.67531723e-03, -5.29084206e-02, -2.17917282e-02,\n",
       "       -2.15483848e-02,  2.42078528e-02, -5.38088381e-02,  7.88582414e-02,\n",
       "        5.78784682e-02, -8.75622686e-03,  1.17978351e-02, -5.98610975e-02,\n",
       "       -3.89093943e-02, -4.03568037e-02,  9.56127048e-03, -4.88754846e-02,\n",
       "       -5.98067092e-03, -7.03285114e-05, -1.70929581e-02,  3.21051367e-02,\n",
       "       -4.89870727e-04, -2.76967436e-02, -1.92175377e-02, -1.10204956e-02,\n",
       "       -1.63527299e-02,  7.46658072e-03,  3.33618298e-02,  5.21345586e-02,\n",
       "        3.62730809e-02, -1.74667649e-02, -8.72591659e-02, -1.05515547e-01,\n",
       "        1.51999220e-02,  4.56567891e-02,  1.11074941e-02,  2.33411342e-02,\n",
       "        2.87761912e-03,  1.09864154e-03, -1.84141770e-02, -2.47193929e-02,\n",
       "       -2.59672254e-02,  5.88000827e-02,  2.43666465e-03,  4.27935570e-02,\n",
       "        2.86981910e-02,  1.07232528e-02,  1.63239054e-03,  8.50377902e-02,\n",
       "       -3.93493138e-02, -1.93156842e-02, -3.37498151e-02, -1.77239757e-02,\n",
       "        4.61079441e-02,  5.96394353e-02,  2.24742740e-02, -4.15105708e-02,\n",
       "       -5.53219430e-02,  3.90256010e-02,  2.45426688e-02, -7.22952932e-03,\n",
       "       -2.05024723e-02, -4.40593660e-02,  6.17876009e-04,  3.32673900e-02,\n",
       "        1.27276620e-02,  4.02303552e-03,  3.82518140e-03, -3.22711580e-02,\n",
       "        3.52407210e-02, -1.99103877e-02,  3.30878608e-02, -1.09993825e-02,\n",
       "       -2.44859587e-02, -7.36303851e-02,  3.51273865e-02, -5.88374538e-03,\n",
       "       -3.56168263e-02,  4.04758155e-02, -6.82337731e-02,  7.06939623e-02,\n",
       "        5.67084365e-03,  5.80100575e-03, -5.26704304e-02,  8.29921663e-03,\n",
       "       -1.43274842e-02, -4.13037799e-02, -9.75811109e-02, -1.46031873e-02,\n",
       "        1.83030479e-02,  1.18014179e-02,  2.40440145e-02, -5.65721728e-02,\n",
       "        4.41038795e-02,  4.49208058e-02,  4.94576953e-02,  3.47248800e-02,\n",
       "        7.71416500e-02,  4.46148776e-03, -6.98717684e-03,  1.41460923e-02,\n",
       "        1.68113206e-02,  1.73571948e-02, -7.72081614e-02, -4.53034341e-02,\n",
       "        3.08932923e-03, -6.12822063e-02,  1.25445770e-02,  3.65402587e-02,\n",
       "       -6.47862181e-02,  1.07536362e-02, -6.00544922e-02, -6.37256429e-02,\n",
       "       -2.87758629e-03, -6.36920193e-03, -2.37967521e-02, -1.35421939e-02,\n",
       "        4.59058629e-03, -1.28184361e-02,  1.59459244e-02,  1.67852230e-02,\n",
       "       -2.29441021e-02, -1.38541982e-01,  4.71086092e-02, -3.53836715e-02,\n",
       "        7.59680523e-03,  2.21695844e-02, -3.57704945e-02, -4.50873114e-02,\n",
       "        7.51984259e-03, -4.69435640e-02, -2.71456633e-02, -1.01650050e-02,\n",
       "        7.59293064e-02, -8.47570673e-02,  3.05887368e-02,  2.33418029e-02,\n",
       "       -8.93589389e-03, -4.31458093e-02,  3.45842056e-02,  3.75819206e-02,\n",
       "        2.51798350e-02,  8.16680770e-03,  4.10834737e-02,  2.97557544e-02,\n",
       "        7.50660822e-02,  2.79709627e-03,  3.95706631e-02,  5.69978319e-02,\n",
       "        1.34438546e-02,  8.42008218e-02,  3.77566852e-02,  1.33640682e-02,\n",
       "       -3.92586030e-02,  6.71552354e-03, -5.34894876e-02, -2.75732055e-02,\n",
       "       -3.02065481e-02, -3.62414750e-03, -3.07444930e-02, -4.53084856e-02,\n",
       "        4.19432037e-02, -7.53870094e-03, -4.43957634e-02, -6.58293292e-02,\n",
       "       -2.43871212e-02,  5.09195449e-03,  6.11493597e-03,  4.22736295e-02,\n",
       "        1.43975578e-02, -2.86321286e-02, -5.32300472e-02,  1.14955509e-03,\n",
       "        1.93387512e-02,  2.10827608e-02, -4.71902527e-02, -8.21943879e-02,\n",
       "       -3.97515297e-02,  8.73352308e-03,  3.82100232e-02,  4.06445563e-02,\n",
       "        6.43950254e-02, -1.08620552e-02,  6.87971488e-02, -3.75614804e-03,\n",
       "       -2.18208078e-02, -4.42599542e-02, -1.10390587e-02, -2.16069873e-02,\n",
       "        2.24194373e-03,  2.77418550e-02,  2.20657829e-02,  3.21475416e-02,\n",
       "        4.69058985e-03, -1.83606893e-02,  4.48339470e-02, -7.47404667e-03,\n",
       "        5.55987172e-02,  3.46675925e-02, -5.79185672e-02, -2.55066156e-02,\n",
       "       -4.81901653e-02, -4.13213633e-02,  8.39533564e-03,  3.69162671e-02,\n",
       "        3.06319091e-02,  6.92121824e-03,  7.16584399e-02,  5.08063920e-02,\n",
       "        3.91985290e-02,  6.24163039e-02,  4.59587574e-02, -2.31610090e-02,\n",
       "       -3.12660821e-02, -3.26108150e-02, -4.00830433e-03, -6.83855340e-02,\n",
       "       -6.22367375e-02, -1.27960145e-02, -1.37146795e-02,  1.73479319e-04,\n",
       "        2.07963400e-03,  6.08999841e-03, -4.50882828e-03, -6.65204599e-04,\n",
       "        1.70147959e-02,  1.95919909e-02, -2.97496244e-02,  3.72215398e-02,\n",
       "        5.68759479e-02,  2.14050040e-02,  6.12818114e-02, -6.04423098e-02,\n",
       "       -2.38947328e-02, -5.89854680e-02, -2.80538108e-02,  7.44818524e-03,\n",
       "        4.82298471e-02, -6.58046678e-02, -2.56829578e-02,  3.19053121e-02,\n",
       "        5.42555610e-03, -1.13314763e-02,  1.15655269e-03,  7.62621872e-03,\n",
       "       -8.62646848e-05,  7.09470287e-02,  2.39687599e-03,  5.57048023e-02,\n",
       "       -6.76661357e-02,  1.94245372e-02, -6.07936047e-02,  1.10484622e-02,\n",
       "        1.60685200e-02, -5.92308342e-02,  1.17053874e-02, -7.43620098e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.get_mean_vector(\"rohan go to hell bhai\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f917100-195a-4369-9dc1-743eaf482713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproces_and_vectorise(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_punct or token.is_stop:\n",
    "            continue\n",
    "        else:\n",
    "            filtered_tokens.append(token.lemma_)\n",
    "\n",
    "    # return filtered_tokens\n",
    "    return wv.get_mean_vector(filtered_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "70dee91b-9108-4bb1-9f9d-446b908ffd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.39975299e-02,  5.99554069e-02,  1.10697998e-02,  9.99219809e-03,\n",
       "       -3.79620604e-02,  1.67734940e-02,  8.44693109e-02, -7.07133934e-02,\n",
       "        1.75194647e-02,  2.92390212e-02,  3.81497107e-02, -4.06724215e-02,\n",
       "       -5.07007213e-03,  3.25688720e-03, -1.16891572e-02, -2.00686622e-02,\n",
       "        2.01555211e-02,  7.59415030e-02,  3.72140817e-02,  2.01925188e-02,\n",
       "       -2.96840072e-02, -8.74600559e-03,  4.66952659e-02,  1.03209801e-02,\n",
       "        5.26380725e-02,  1.44286351e-02,  6.07050350e-03,  1.85698327e-02,\n",
       "        4.27841134e-02, -4.09047492e-02,  4.21923399e-02,  4.14358824e-02,\n",
       "       -1.12875775e-02, -7.02442303e-02,  2.56184731e-02, -9.28569585e-04,\n",
       "        2.87378523e-02, -2.83987378e-03,  2.21365932e-02,  4.66248803e-02,\n",
       "        5.56333177e-02, -5.91642857e-02,  9.80953649e-02,  1.62769817e-02,\n",
       "       -2.55392697e-02,  7.17245415e-03, -1.00133540e-02,  3.83169092e-02,\n",
       "       -2.36312151e-02,  2.80451495e-02, -4.69411276e-02,  7.78737739e-02,\n",
       "       -2.23916024e-03,  5.21153621e-02, -1.13778142e-02, -1.53957633e-02,\n",
       "        7.15446472e-03,  3.12621891e-02,  6.71373010e-02, -5.04272394e-02,\n",
       "        4.11798013e-03,  4.97788787e-02, -4.35450114e-02,  9.77054518e-03,\n",
       "        3.49336979e-03, -1.81870477e-03, -5.74255101e-02,  6.58261999e-02,\n",
       "       -3.04956380e-02,  1.86118239e-03,  5.19537292e-02,  3.67890112e-02,\n",
       "        2.06500236e-02, -1.01538813e-02, -1.19508147e-01, -3.69794220e-02,\n",
       "        3.89092341e-02,  3.75699736e-02,  2.36069039e-02,  3.69351469e-02,\n",
       "       -6.17922610e-03,  4.31511737e-02,  4.20200117e-02,  5.50547801e-02,\n",
       "       -2.13050991e-02, -5.40539622e-04, -7.11801276e-02,  8.89044181e-02,\n",
       "        6.53384626e-02,  1.17469281e-02, -2.44213045e-02,  4.55418639e-02,\n",
       "       -6.84767738e-02, -1.37582079e-01, -4.43387516e-02, -4.94599603e-02,\n",
       "        5.09124063e-02,  2.10356992e-02, -4.40680943e-02, -2.38097999e-02,\n",
       "       -4.40331101e-02, -2.52130833e-02,  3.41927372e-02,  7.50922635e-02,\n",
       "       -2.09918153e-02, -8.28315318e-03,  2.45255847e-02, -1.44034466e-02,\n",
       "        4.98245955e-02, -4.26512249e-02, -2.59028226e-02,  8.07831064e-03,\n",
       "        1.66229829e-02, -3.44007500e-02,  3.44521813e-02, -2.93997228e-02,\n",
       "        8.87634512e-03, -2.83154082e-02,  5.05961338e-03,  1.21541694e-02,\n",
       "       -6.77636340e-02,  3.62207624e-03,  1.00431023e-02,  2.23077461e-02,\n",
       "        1.27911093e-02, -5.27764745e-02, -6.41698763e-02, -3.27556580e-02,\n",
       "       -2.90118363e-02, -2.41143163e-02, -1.23512521e-02, -5.30837178e-02,\n",
       "       -1.93796009e-02,  3.42510119e-02, -6.61717057e-02, -5.52137196e-02,\n",
       "        9.17080976e-03,  3.82591225e-02,  7.02975551e-03,  5.46493642e-02,\n",
       "       -3.78617346e-02, -1.03776343e-02,  5.55679612e-02, -3.27649079e-02,\n",
       "       -5.82620269e-03,  1.70702916e-02, -3.62576507e-02, -5.36688305e-02,\n",
       "        9.81015060e-03, -4.05635871e-02,  6.07646666e-02,  4.56117354e-02,\n",
       "       -1.42969787e-02,  1.21651320e-02, -2.38713771e-02, -3.19270021e-03,\n",
       "       -3.36463265e-02, -5.60049154e-02, -4.84682713e-03, -9.36029200e-03,\n",
       "       -2.88731903e-02,  5.50969988e-02,  2.49726195e-02,  1.13804443e-02,\n",
       "        5.30946068e-02, -3.54917087e-02, -6.38570078e-03, -4.00836542e-02,\n",
       "        7.77184144e-02, -1.41877169e-02, -9.54352096e-02, -3.87362279e-02,\n",
       "       -2.06780266e-02, -2.16225591e-02, -2.86031812e-02, -3.51877697e-03,\n",
       "        5.92635572e-02,  2.32099486e-03, -8.08408037e-02,  5.57011403e-02,\n",
       "       -5.08688875e-02, -4.04151641e-02,  4.05752808e-02,  3.57693359e-02,\n",
       "       -3.77132237e-04, -4.94689532e-02, -3.11173629e-02,  4.12433781e-02,\n",
       "        2.59548277e-02, -2.53310781e-02,  4.31570224e-02, -2.94402000e-02,\n",
       "        7.35898912e-02,  3.22677679e-02,  1.86303444e-02,  3.08906492e-02,\n",
       "        3.77586931e-02,  3.76783609e-02, -4.88412790e-02, -1.87397916e-02,\n",
       "       -2.07070541e-02,  1.94061603e-02, -2.80839652e-02, -5.88722527e-02,\n",
       "        6.79279910e-03,  2.03940347e-02, -6.22412143e-03,  4.07517366e-02,\n",
       "        2.94082891e-02, -4.75489683e-02, -2.13050959e-03,  6.80453330e-02,\n",
       "       -3.46762352e-02,  4.59755445e-03, -3.16538773e-02,  2.06435136e-02,\n",
       "       -9.68816504e-03,  2.12120656e-02, -9.76763591e-02, -4.42767330e-03,\n",
       "       -1.78493336e-02, -2.36175526e-02, -4.02895585e-02, -1.10359984e-02,\n",
       "       -8.68278369e-03,  8.86141229e-03,  1.09113632e-02,  1.21912388e-02,\n",
       "       -2.28925887e-02,  4.38324958e-02,  1.51930051e-02, -4.17735167e-02,\n",
       "       -3.73599418e-02,  2.87404563e-03, -2.28924211e-02,  7.02558011e-02,\n",
       "        2.25972268e-03, -2.50186026e-02,  3.18321995e-02,  2.26268526e-02,\n",
       "        1.51933683e-02, -1.96543802e-02,  8.27269163e-03, -3.94133143e-02,\n",
       "       -2.14232015e-03,  8.17761794e-02,  1.88985616e-02,  5.96627258e-02,\n",
       "        7.03735417e-03, -1.17287608e-02,  2.06958745e-02,  3.54438797e-02,\n",
       "        9.05294642e-02,  9.42312554e-03, -2.99882367e-02, -3.39567252e-02,\n",
       "       -5.33733377e-03, -1.56247960e-02, -1.28409080e-02,  1.11110928e-02,\n",
       "       -5.86660840e-02,  5.41277230e-02, -9.51836482e-05,  4.01646979e-02,\n",
       "        5.31955101e-02,  5.37434816e-02, -9.89479478e-03,  5.09493984e-04,\n",
       "       -4.73161899e-02,  1.81297008e-02,  6.77736774e-02,  9.03474092e-02,\n",
       "        1.47721693e-01,  1.67149082e-02, -4.08435846e-03, -4.65153046e-02,\n",
       "       -3.72012816e-02, -5.93798757e-02,  6.13544276e-03, -1.34502305e-02,\n",
       "        2.24530343e-02, -5.84072508e-02, -1.64465457e-02,  5.58165498e-02,\n",
       "       -3.89097892e-02,  2.67335717e-02,  2.13452335e-03,  3.63024510e-02,\n",
       "       -5.85742528e-03,  1.75349880e-02, -3.63488458e-02,  3.47153656e-02,\n",
       "       -4.14583236e-02, -1.81044582e-02, -2.60550138e-02, -2.10886300e-02,\n",
       "       -1.14862891e-02, -5.38533330e-02,  2.86721382e-02, -9.69879329e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproces_and_vectorise('I want to go home I am so tired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc14fe-70f4-47ee-aa2e-f6b10581076c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
